{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image108.jpg', 'image88.jpg']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "#crop image to middle\n",
    "image_width = 500\n",
    "image_height = 500\n",
    "input_path = \"input_photos\"\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "included_extensions = ['jpg', 'bmp', 'png', 'gif']\n",
    "onlyfiles = [fn for fn in os.listdir(input_path)\n",
    "              if any(fn.endswith(ext) for ext in included_extensions)]\n",
    "\n",
    "onlyfiles[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from numpy import*\n",
    "\n",
    "frames = []\n",
    "def newFrame(cur_filepath):\n",
    "    temp=Image.open(cur_filepath)\n",
    "    temp=temp.convert('1')      # Convert to black&white\n",
    "    A = array(temp)             # Creates an array, white pixels==True and black pixels==False\n",
    "    new_A=empty((A.shape[0],A.shape[1]),None)    #New array with same size as A\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(A[i])):\n",
    "            if A[i][j]==True:\n",
    "                new_A[i][j]=0\n",
    "            else:\n",
    "                new_A[i][j]=1\n",
    "    frames.append(new_A)\n",
    "\n",
    "for x in onlyfiles:\n",
    "    newFrame(input_path + \"/\" + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "x = []\n",
    "def middle_out(frame1, frame2, frame3):\n",
    "    target.append([frame2])\n",
    "    x.append([frame1,frame3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,5):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_out_frames(cur_scene):\n",
    "    for idx in range(0,len(cur_scene)-2):\n",
    "        middle_out(cur_scene[idx], cur_scene[idx + 1], cur_scene[idx + 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d5a93703cc22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    # Create input and target placeholder.\n",
    "    input_placeholder = tf.placeholder(tf.float32, shape=(None, 720, 1280, 2))\n",
    "    target_placeholder = tf.placeholder(tf.float32, shape=(None, 720, 1280, 1))\n",
    "\n",
    "    # input_resized = tf.image.resize_area(input_placeholder, [128, 128])\n",
    "    # target_resized = tf.image.resize_area(target_placeholder,[128, 128])\n",
    "\n",
    "    # Prepare model.\n",
    "    model = Voxel_flow_model()\n",
    "    prediction = model.inference(input_placeholder)\n",
    "    # reproduction_loss, prior_loss = model.loss(prediction, target_placeholder)\n",
    "    reproduction_loss = model.loss(prediction, target_placeholder)\n",
    "    # total_loss = reproduction_loss + prior_loss\n",
    "    total_loss = reproduction_loss\n",
    "\n",
    "    # Perform learning rate scheduling.\n",
    "    learning_rate = FLAGS.initial_learning_rate\n",
    "\n",
    "    # Create an optimizer that performs gradient descent.\n",
    "    opt = tf.train.AdamOptimizer(learning_rate)\n",
    "    grads = opt.compute_gradients(total_loss)\n",
    "    update_op = opt.apply_gradients(grads)\n",
    "\n",
    "    # Create summaries\n",
    "    summaries = tf.get_collection(tf.GraphKeys.SUMMARIES)\n",
    "    summaries.append(tf.scalar_summary('total_loss', total_loss))\n",
    "    summaries.append(tf.scalar_summary('reproduction_loss', reproduction_loss))\n",
    "    # summaries.append(tf.scalar_summary('prior_loss', prior_loss))\n",
    "    summaries.append(tf.image_summary('Input Image', input_placeholder, 3))\n",
    "    summaries.append(tf.image_summary('Output Image', prediction, 3))\n",
    "    summaries.append(tf.image_summary('Target Image', target_placeholder, 3))\n",
    "\n",
    "    # Create a saver.\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "    # Build the summary operation from the last tower summaries.\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Summary Writter\n",
    "    summary_writer = tf.train.SummaryWriter(\n",
    "        FLAGS.train_dir,\n",
    "        graph=sess.graph)\n",
    "\n",
    "    # Training loop using feed dict method.\n",
    "    data_list_frame1 = dataset_frame1.read_data_list_file()\n",
    "    random.seed(1)\n",
    "    shuffle(data_list_frame1)\n",
    "\n",
    "    data_list_frame2 = dataset_frame2.read_data_list_file()\n",
    "    random.seed(1)\n",
    "    shuffle(data_list_frame2)\n",
    "\n",
    "    data_list_frame3 = dataset_frame3.read_data_list_file()\n",
    "    random.seed(1)\n",
    "    shuffle(data_list_frame3)\n",
    "\n",
    "    data_size = len(data_list_frame1)\n",
    "    epoch_num = int(data_size / FLAGS.batch_size)\n",
    "\n",
    "    # num_workers = 1\n",
    "\n",
    "    # load_fn_frame1 = partial(dataset_frame1.process_func)\n",
    "    # p_queue_frame1 = PrefetchQueue(load_fn_frame1, data_list_frame1, FLAGS.batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    # load_fn_frame2 = partial(dataset_frame2.process_func)\n",
    "    # p_queue_frame2 = PrefetchQueue(load_fn_frame2, data_list_frame2, FLAGS.batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    # load_fn_frame3 = partial(dataset_frame3.process_func)\n",
    "    # p_queue_frame3 = PrefetchQueue(load_fn_frame3, data_list_frame3, FLAGS.batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    for step in xrange(0, FLAGS.max_steps):\n",
    "      batch_idx = step % epoch_num\n",
    "\n",
    "      batch_data_list_frame1 = data_list_frame1[int(\n",
    "          batch_idx * FLAGS.batch_size): int((batch_idx + 1) * FLAGS.batch_size)]\n",
    "      batch_data_list_frame2 = data_list_frame2[int(\n",
    "          batch_idx * FLAGS.batch_size): int((batch_idx + 1) * FLAGS.batch_size)]\n",
    "      batch_data_list_frame3 = data_list_frame3[int(\n",
    "          batch_idx * FLAGS.batch_size): int((batch_idx + 1) * FLAGS.batch_size)]\n",
    "\n",
    "      # Load batch data.\n",
    "      batch_data_frame1 = np.array(\n",
    "          [dataset_frame1.process_func(line) for line in batch_data_list_frame1])\n",
    "      batch_data_frame2 = np.array(\n",
    "          [dataset_frame2.process_func(line) for line in batch_data_list_frame2])\n",
    "      batch_data_frame3 = np.array(\n",
    "          [dataset_frame3.process_func(line) for line in batch_data_list_frame3])\n",
    "\n",
    "      # batch_data_frame1 = p_queue_frame1.get_batch()\n",
    "      # batch_data_frame2 = p_queue_frame2.get_batch()\n",
    "      # batch_data_frame3 = p_queue_frame3.get_batch()\n",
    "\n",
    "      feed_dict = {input_placeholder: np.concatenate(\n",
    "          (batch_data_frame1, batch_data_frame3), 3), target_placeholder: batch_data_frame2}\n",
    "\n",
    "      # Run single step update.\n",
    "      _, loss_value = sess.run([update_op, total_loss], feed_dict=feed_dict)\n",
    "\n",
    "      if batch_idx == 0:\n",
    "        # Shuffle data at each epoch.\n",
    "        random.seed(1)\n",
    "        shuffle(data_list_frame1)\n",
    "        random.seed(1)\n",
    "        shuffle(data_list_frame2)\n",
    "        random.seed(1)\n",
    "        shuffle(data_list_frame3)\n",
    "        print('Epoch Number: %d' % int(step / epoch_num))\n",
    "\n",
    "      # Output Summary\n",
    "      if step % 10 == 0:\n",
    "        # summary_str = sess.run(summary_op, feed_dict = feed_dict)\n",
    "        # summary_writer.add_summary(summary_str, step)\n",
    "\t      print(\"Loss at step %d: %f\" % (step, loss_value))\n",
    "\n",
    "      if step % 500 == 0:\n",
    "        # Run a batch of images\n",
    "        prediction_np, target_np = sess.run(\n",
    "            [prediction, target_placeholder], feed_dict=feed_dict)\n",
    "        for i in range(0, prediction_np.shape[0]):\n",
    "          file_name = FLAGS.train_image_dir+str(i)+'_out.png'\n",
    "          file_name_label = FLAGS.train_image_dir+str(i)+'_gt.png'\n",
    "          imwrite(file_name, prediction_np[i, :, :, :])\n",
    "          imwrite(file_name_label, target_np[i, :, :, :])\n",
    "\n",
    "      # Save checkpoint\n",
    "      if step % 5000 == 0 or (step + 1) == FLAGS.max_steps:\n",
    "        checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n",
    "        saver.save(sess, checkpoint_path, global_step=step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
